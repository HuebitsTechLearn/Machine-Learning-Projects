# Document Scanner with OCR and ML Enhancement

## Project Structure
```
doc_scanner/
├── data/
│   └── sample_docs/
├── scanner.py
├── requirements.txt
├── README.md
└── output/
```

---

## requirements.txt
```
opencv-python
numpy
pytesseract
Pillow
scikit-learn
streamlit
```

---

## scanner.py
```python
import cv2
import numpy as np
import pytesseract
import streamlit as st
from PIL import Image
import os
import datetime

pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Update this path as needed

# Utility: Apply preprocessing to enhance OCR accuracy
def preprocess_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edged = cv2.Canny(blurred, 75, 200)
    return edged

# Utility: Detect document contours and apply perspective transform
def get_scanned_image(image):
    orig = image.copy()
    edged = preprocess_image(image)
    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]

    for c in contours:
        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)
        if len(approx) == 4:
            doc_cnt = approx
            break
    else:
        return orig  # fallback if no contour found

    pts = doc_cnt.reshape(4, 2)
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]

    (tl, tr, br, bl) = rect
    widthA = np.linalg.norm(br - bl)
    widthB = np.linalg.norm(tr - tl)
    heightA = np.linalg.norm(tr - br)
    heightB = np.linalg.norm(tl - bl)
    maxWidth = max(int(widthA), int(widthB))
    maxHeight = max(int(heightA), int(heightB))

    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]], dtype="float32")

    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(orig, M, (maxWidth, maxHeight))
    return cv2.cvtColor(warped, cv2.COLOR_BGR2RGB)

# OCR
def extract_text(img):
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    text = pytesseract.image_to_string(thresh)
    return text

# Save output
def save_text(text):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    path = f"output/scanned_{timestamp}.txt"
    with open(path, "w") as f:
        f.write(text)
    return path

# Streamlit UI
st.title("Document Scanner with OCR")
option = st.radio("Upload or Use Webcam", ('Upload Image', 'Use Webcam'))

if option == 'Upload Image':
    uploaded_file = st.file_uploader("Upload Document Image", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        img = Image.open(uploaded_file)
        img = np.array(img)
        scanned = get_scanned_image(img)
        st.image(scanned, caption='Scanned Image')
        text = extract_text(scanned)
        st.text_area("Extracted Text", text, height=300)
        path = save_text(text)
        st.success(f"Text saved to {path}")
else:
    st.warning("Live webcam scanning is under development.")
```

---

## README.md
```markdown
# Document Scanner with OCR and ML Enhancement

This project turns your webcam or uploaded image into a smart document scanner. It detects, flattens, enhances, and extracts text from documents using OpenCV and Tesseract OCR.

## Features
- Real-time edge detection
- Perspective transformation
- Text extraction
- UI with Streamlit
- Saves output to .txt

## Requirements
```bash
pip install -r requirements.txt
```

## Run the App
```bash
streamlit run scanner.py
```
---
> Built for digitization tasks in offices, education, and fintech domains.
```
