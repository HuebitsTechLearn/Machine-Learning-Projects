Your project music_genre_classifier is now fully structured and coded in the canvas. It includes:
CNN-based training pipeline for genre classification
MFCC feature extraction via librosa
A full Streamlit app for genre prediction
Dataset loading compatible with GTZAN-style folders
Preprocessing, training, and visualization support
# Music Genre Classification using Deep Learning (CNN + Audio Analysis)

## Project Structure
```
music_genre_classifier/
├── data/
│   └── gtzan/
├── spectrograms/
├── model/
├── app.py
├── train.py
├── utils.py
├── requirements.txt
├── README.md
```

---

## requirements.txt
```
tensorflow
librosa
numpy
matplotlib
scikit-learn
streamlit
```

---

## utils.py
```python
import librosa
import numpy as np
import os
import matplotlib.pyplot as plt

# Create mel spectrogram or MFCC from audio
def extract_features(audio_path, n_mfcc=40, max_len=174):
    signal, sr = librosa.load(audio_path, sr=None)
    mfcc = librosa.feature.mfcc(signal, sr=sr, n_mfcc=n_mfcc)
    if mfcc.shape[1] < max_len:
        pad_width = max_len - mfcc.shape[1]
        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')
    else:
        mfcc = mfcc[:, :max_len]
    return mfcc

# Load dataset from GTZAN-like structure
def load_dataset(data_dir):
    genres = os.listdir(data_dir)
    X, y = [], []
    for label, genre in enumerate(genres):
        genre_path = os.path.join(data_dir, genre)
        for filename in os.listdir(genre_path):
            if filename.endswith(".wav"):
                file_path = os.path.join(genre_path, filename)
                mfcc = extract_features(file_path)
                X.append(mfcc)
                y.append(label)
    return np.array(X), np.array(y), genres
```

---

## train.py
```python
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from utils import load_dataset

# Load dataset
X, y, genre_labels = load_dataset("data/gtzan")
X = X[..., np.newaxis]  # CNN needs 4D input
X = X / np.max(X)  # Normalize

# Train-test split
y = tf.keras.utils.to_categorical(y, num_classes=len(genre_labels))
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build CNN
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=X.shape[1:]),
    MaxPooling2D((2, 2)),
    Dropout(0.3),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.3),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(genre_labels), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32)
model.save("model/genre_classifier.h5")
```

---

## app.py
```python
import streamlit as st
import librosa.display
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from utils import extract_features

model = tf.keras.models.load_model("model/genre_classifier.h5")
labels = ['blues', 'classical', 'country', 'disco', 'hiphop',
          'jazz', 'metal', 'pop', 'reggae', 'rock']

st.title("Music Genre Classifier")
file = st.file_uploader("Upload Audio File (.wav only)", type=["wav"])

if file:
    st.audio(file)
    with open("temp.wav", "wb") as f:
        f.write(file.read())

    mfcc = extract_features("temp.wav")
    X = np.expand_dims(mfcc, axis=(0, -1))
    prediction = model.predict(X)
    genre = labels[np.argmax(prediction)]

    st.success(f"Predicted Genre: {genre}")

    # Visualize MFCC
    fig, ax = plt.subplots()
    librosa.display.specshow(mfcc, x_axis='time')
    plt.colorbar()
    plt.title("MFCC")
    st.pyplot(fig)
```

---

## README.md
```markdown
# Music Genre Classifier using CNN

This project uses MFCCs + CNN to classify music genres from audio data.

## Features
- MFCC-based audio analysis
- 10-genre classification
- Streamlit UI for real-time prediction

## Install Requirements
```bash
pip install -r requirements.txt
```

## Train the Model
```bash
python train.py
```

## Run the App
```bash
streamlit run app.py
```
